# ğŸ¯ Prochaines Ã©tapes - Guide d'utilisation

## âœ… Ã‰tat actuel

- âœ… **DonnÃ©es nettoyÃ©es** : 3,035 tweets clients (fichier `tweets_cleaned.parquet`)
- âŒ **DonnÃ©es enrichies** : Pas encore (besoin de l'enrichissement LLM)

## ğŸš€ Ã‰tape suivante : Enrichissement LLM

Vous devez maintenant enrichir vos tweets avec les classifications LLM (sentiment, motif, urgence, churn).

### Option 1 : Pipeline complet (recommandÃ©)

ExÃ©cutez le pipeline complet qui va :
1. Charger les donnÃ©es nettoyÃ©es
2. Enrichir avec Mistral LLM
3. Sauvegarder le rÃ©sultat final

```bash
python main.py
```

**âš ï¸ Important :** Vous devez avoir configurÃ© votre clÃ© API Mistral dans un fichier `.env` :

```env
MISTRAL_API_KEY=votre_clÃ©_api_ici
```

### Option 2 : Enrichissement uniquement (si donnÃ©es dÃ©jÃ  nettoyÃ©es)

Si vous voulez juste enrichir les donnÃ©es dÃ©jÃ  nettoyÃ©es :

```python
from src.pipeline_enrichment import enrich_with_llm
from src.utils import load_dataframe, save_dataframe
from pathlib import Path
import pandas as pd

# Charger les donnÃ©es nettoyÃ©es
df = load_dataframe(Path("data/processed/tweets_cleaned.parquet"))

# Enrichir avec LLM
df_enriched = enrich_with_llm(
    df,
    text_col="text_clean",
    checkpoint_path=Path("data/processed/checkpoint.parquet")
)

# Sauvegarder
save_dataframe(df_enriched, Path("data/processed/tweets_enriched.parquet"))
```

## ğŸ“‹ Checklist avant de lancer

- [ ] ClÃ© API Mistral configurÃ©e dans `.env`
- [ ] DÃ©pendances installÃ©es (`pip install -r requirements.txt`)
- [ ] ModÃ¨le spaCy installÃ© (`python -m spacy download fr_core_news_sm`)
- [ ] Fichier `tweets_cleaned.parquet` existe (âœ… dÃ©jÃ  fait)

## â±ï¸ Temps estimÃ©

Pour 3,035 tweets :
- **Temps estimÃ©** : 15-30 minutes (selon votre connexion et le modÃ¨le Mistral)
- **CoÃ»t estimÃ©** : ~$0.50-$2.00 (selon le modÃ¨le utilisÃ©)

## ğŸ¨ AprÃ¨s l'enrichissement : Dashboard

Une fois l'enrichissement terminÃ©, lancez le dashboard :

```bash
streamlit run app/streamlit_app.py
```

Le dashboard affichera :
- ğŸ“Š KPIs (sentiment, urgence, churn)
- ğŸ“ˆ Graphiques temporels
- ğŸ¯ Analyse par motif
- ğŸ“‹ Liste des tweets avec filtres

## ğŸ”§ Configuration

### ModÃ¨le Mistral

Par dÃ©faut : `mistral-medium-latest` (plus prÃ©cis, plus cher)

Pour rÃ©duire les coÃ»ts, modifiez `.env` :
```env
MISTRAL_MODEL=mistral-small-latest
```

### Taille des batches

Par dÃ©faut : 20 tweets par batch

Pour modifier, Ã©ditez `src/config.py` :
```python
LLM_BATCH_SIZE = 20  # Augmentez pour aller plus vite (risque rate limit)
```

## ğŸ“Š VÃ©rification

AprÃ¨s l'enrichissement, vÃ©rifiez que les colonnes sont prÃ©sentes :

```python
import pandas as pd
df = pd.read_parquet("data/processed/tweets_enriched.parquet")
print(df.columns)
# Doit contenir: motif, sentiment, urgence, risque_churn, is_churn_risk
```

## ğŸ†˜ ProblÃ¨mes courants

### Erreur "MISTRAL_API_KEY non dÃ©finie"
â†’ CrÃ©ez un fichier `.env` avec votre clÃ© API

### Rate limit API
â†’ Le pipeline gÃ¨re automatiquement les pauses. Attendez quelques minutes et relancez.

### Interruption du traitement
â†’ Le pipeline sauvegarde un checkpoint. Relancez simplement `python main.py` pour reprendre.

### CoÃ»ts trop Ã©levÃ©s
â†’ Utilisez `mistral-small-latest` au lieu de `mistral-medium-latest`

## ğŸ“ Besoin d'aide ?

Consultez :
- `README.md` : Documentation complÃ¨te
- `QUICKSTART.md` : Guide de dÃ©marrage rapide
- `DOC_CLEANING.md` : Documentation du nettoyage
- `DOC_FILTRE_FREE.md` : Documentation du filtrage Free

